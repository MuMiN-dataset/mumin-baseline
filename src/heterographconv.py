'''Copy of dglnn.HeteroGraphConv, with canonical etype compatibility'''

import torch
import torch.nn as nn
from dgl import DGLError
from functools import partial


class HeteroGraphConv(nn.Module):
    '''Copy of dglnn.HeteroGraphConv, with canonical etype compatibility'''

    def __init__(self, mods, aggregate='sum'):
        super(HeteroGraphConv, self).__init__()
        self.mods = nn.ModuleDict({'_'.join(etype): val
                                   for etype, val in mods.items()})
        # Do not break if graph has 0-in-degree nodes.
        # Because there is no general rule to add self-loop for heterograph.
        for _, v in self.mods.items():
            set_allow_zero_in_degree_fn = getattr(v,
                                                  'set_allow_zero_in_degree',
                                                  None)
            if callable(set_allow_zero_in_degree_fn):
                set_allow_zero_in_degree_fn(True)
        if isinstance(aggregate, str):
            self.agg_fn = self.get_aggregate_fn(aggregate)
        else:
            self.agg_fn = aggregate

    def forward(self, g, inputs, mod_args=None, mod_kwargs=None):
        """Forward computation

        Invoke the forward function with each module and aggregate their results.

        Parameters
        ----------
        g : DGLHeteroGraph
            Graph data.
        inputs : dict[str, Tensor] or pair of dict[str, Tensor]
            Input node features.
        mod_args : dict[str, tuple[any]], optional
            Extra positional arguments for the sub-modules.
        mod_kwargs : dict[str, dict[str, any]], optional
            Extra key-word arguments for the sub-modules.

        Returns
        -------
        dict[str, Tensor]
            Output representations for every types of nodes.
        """
        if mod_args is None:
            mod_args = {}
        if mod_kwargs is None:
            mod_kwargs = {}
        outputs = {nty : [] for nty in g.dsttypes}
        if isinstance(inputs, tuple) or g.is_block:
            if isinstance(inputs, tuple):
                src_inputs, dst_inputs = inputs
            else:
                src_inputs = inputs
                dst_inputs = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}

            for stype, etype, dtype in g.canonical_etypes:
                rel_graph = g[stype, etype, dtype]
                if rel_graph.number_of_edges() == 0:
                    continue
                if stype not in src_inputs or dtype not in dst_inputs:
                    continue
                dstdata = self.mods[f'{stype}_{etype}_{dtype}'](
                    rel_graph,
                    (src_inputs[stype], dst_inputs[dtype]),
                    *mod_args.get(etype, ()),
                    **mod_kwargs.get(etype, {}))
                outputs[dtype].append(dstdata)
        else:
            for stype, etype, dtype in g.canonical_etypes:
                rel_graph = g[stype, etype, dtype]
                if rel_graph.number_of_edges() == 0:
                    continue
                if stype not in inputs:
                    continue
                dstdata = self.mods[f'{stype}_{etype}_{dtype}'](
                    rel_graph,
                    (inputs[stype], inputs[dtype]),
                    *mod_args.get(etype, ()),
                    **mod_kwargs.get(etype, {}))
                outputs[dtype].append(dstdata)
        rsts = {}
        for nty, alist in outputs.items():
            if len(alist) != 0:
                rsts[nty] = self.agg_fn(alist, nty)
        return rsts

    def get_aggregate_fn(self, agg):
        """Internal function to get the aggregation function for node data
        generated from different relations.

        Parameters
        ----------
        agg : str
            Method for aggregating node features generated by different relations.
            Allowed values are 'sum', 'max', 'min', 'mean', 'stack'.

        Returns
        -------
        callable
            Aggregator function that takes a list of tensors to aggregate
            and returns one aggregated tensor.
        """
        if agg == 'sum':
            fn = self._sum_reduce_func
        elif agg == 'max':
            fn = self._max_reduce_func
        elif agg == 'min':
            fn = self._min_reduce_func
        elif agg == 'mean':
            fn = self._mean_reduce_func
        elif agg == 'stack':
            fn = None  # will not be called
        else:
            raise DGLError(f'Invalid cross type aggregator. Must be one of '
                           f'"sum", "max", "min", "mean" or "stack". But got '
                           f'"{agg}"')
        if agg == 'stack':
            return self._stack_agg_func
        else:
            return partial(self._agg_func, fn=fn)

    @staticmethod
    def _max_reduce_func(inputs, dim):
        return torch.max(inputs, dim=dim)[0]

    @staticmethod
    def _min_reduce_func(inputs, dim):
        return torch.min(inputs, dim=dim)[0]

    @staticmethod
    def _sum_reduce_func(inputs, dim):
        return torch.sum(inputs, dim=dim)

    @staticmethod
    def _mean_reduce_func(inputs, dim):
        return torch.mean(inputs, dim=dim)

    @staticmethod
    def _stack_agg_func(inputs, dsttype): # pylint: disable=unused-argument
        if len(inputs) == 0:
            return None
        return torch.stack(inputs, dim=1)

    @staticmethod
    def _agg_func(inputs, dsttype, fn): # pylint: disable=unused-argument
        if len(inputs) == 0:
            return None
        stacked = torch.stack(inputs, dim=0)
        return fn(stacked, dim=0)
